{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn import *\nimport time\n\nimport spacy \nnlp = spacy.load('en_core_web_sm')\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!wget https://raw.githubusercontent.com/google-research/bert/master/modeling.py \n!wget https://raw.githubusercontent.com/google-research/bert/master/extract_features.py \n!wget https://raw.githubusercontent.com/google-research/bert/master/tokenization.py","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!wget https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-12_H-768_A-12.zip\n! 7z x uncased_L-12_H-768_A-12.zip","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def name_replace(s, r1, r2):\n    s = str(s).replace(r1,r2)\n    for r3 in r1.split(' '):\n        s = str(s).replace(r3,r2)\n    return s\n\ndef fill_nlp_tag_empty_cols(df, tag):\n    df[f\"A-{tag}\"] = None\n    df[f\"B-{tag}\"] = None\n    \ndef fill_nlp_empty_cols(df, tags):\n    for tag in tags:\n        fill_nlp_tag_empty_cols(df, tag)\n\ndef fill_word_offset_empty_cols(df):\n    df['Pronoun-word-offset'] = None\n    df['A-word-offset'] = None\n    df['B-word-offset'] = None\n    df['A-word-dist'] = None\n    df['B-word-dist'] = None\n    \ndef word_offset(doc, w):\n    count = 0\n    for token in doc:\n        if token.text == w:\n            break\n        if not token.is_punct and token.text != '`':\n            count += 1\n    return count\n    \ndef fill_similarity(df):\n    df['sim_A_P'] = 0.0\n    df['sim_B_P'] = 0.0\n    \ndef get_nlp_tag_feature(doc, tag):\n    tokens = pd.DataFrame([[token.text, token.dep_] for token in doc], columns=['text', 'dep'])\n    A_tag = len(tokens[((tokens['text']=='subjectone') & (tokens['dep']==tag))])\n    B_tag = len(tokens[((tokens['text']=='subjecttwo') & (tokens['dep']==tag))])\n    \n    return A_tag, B_tag\n\ndef get_similarity(doc, pronoun):\n    A_token, B_token, P_token = None, None, None\n    for token in doc:\n        if token.text == \"subjectone\":\n            A_token = token\n        if token.text == \"subjecttwo\":\n            B_token = token\n        \n        if token.text == pronoun:\n            P_token = token\n            \n    sim_A_P = 0 if A_token is None else A_token.similarity(P_token)\n    sim_B_P = 0 if B_token is None else B_token.similarity(P_token)\n\n    return sim_A_P, sim_B_P\n\ndef sentences_same(s, w1, w2):\n    doc = nlp(str(s))\n    for sent in doc.sents:\n        t1 = False\n        for token in sent:\n            if w1 == token.text:\n                t1 = True\n            if t1 and w2 == token.text:\n                return True\n            elif t1:\n                return False\n            \ndef sentences(s, w1, w2):\n    doc = nlp(str(s))\n    t1, t2 = None\n    for token in doc:\n        if token.text == w1:\n            t1 = token\n        if token.text == w2:\n            t2 = token\n    if t1.sent == t2.sent:\n        return False\n    else:\n        return True\n\ndef add_nlp_features_with_similarirty(df, tags):\n    size = len(df)\n    fill_nlp_empty_cols(df, tags)\n    fill_word_offset_empty_cols(df)\n    \n    for i in range(0, size):\n        text = df.loc[i, 'Text']\n        doc = nlp(str(text))\n        \n        #add tag features\n        for tag in tags:\n            df.loc[i, f\"A-{tag}\"], df.loc[i, f\"B-{tag}\"] = get_nlp_tag_feature(doc, tag)\n            \n        #add word offset features\n        df.loc[i, 'Pronoun-word-offset'] = word_offset(doc, df.loc[i, 'Pronoun'])\n        df.loc[i, 'A-word-offset'] = word_offset(doc, 'subjectone')\n        df.loc[i, 'B-word-offset'] = word_offset(doc, 'subjecttwo')\n        \n        df.loc[i, 'A-word-dist'] = np.abs(df.loc[i, 'Pronoun-word-offset'] - df.loc[i, 'A-word-offset'])\n        df.loc[i, 'B-word-dist'] = np.abs(df.loc[i, 'Pronoun-word-offset'] - df.loc[i, 'B-word-offset'])\n        \n        #add similarity \n        df.loc[i, 'sim_A_P'], df.loc[i, 'sim_B_P'] = get_similarity(doc, df.loc[i, 'Pronoun'])\n\n\n    \ndef add_distance_features(df):\n    df['Pronoun-offset2'] = df['Pronoun-offset'] + df['Pronoun'].map(len)\n    df['A-offset2'] = df['A-offset'] + df['A'].map(len)\n    df['B-offset2'] = df['B-offset'] + df['B'].map(len)\n    df['A-dist'] = (df['Pronoun-offset'] - df['A-offset']).abs()\n    df['B-dist'] = (df['Pronoun-offset'] - df['B-offset']).abs()\n    df['section_min'] = df[['Pronoun-offset', 'A-offset', 'B-offset']].min(axis=1)\n    df['section_max'] = df[['Pronoun-offset2', 'A-offset2', 'B-offset2']].max(axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import modeling\nimport extract_features\nimport tokenization","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def compute_offset_no_spaces(text, offset):\n    count = 0\n    for pos in range(offset):\n        if text[pos] != \" \": count +=1\n    return count\n\ndef count_chars_no_special(text):\n    count = 0\n    special_char_list = [\"#\"]\n    for pos in range(len(text)):\n        if text[pos] not in special_char_list: count +=1\n    return count\n\ndef count_length_no_special(text):\n    count = 0\n    special_char_list = [\"#\", \" \"]\n    for pos in range(len(text)):\n        if text[pos] not in special_char_list: count +=1\n    return count","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def bert_embeddings(df):\n    text = df[\"Text\"]\n    text.to_csv(\"input.txt\", index = False, header = False)\n    \n    # run BERT model\n    os.system(\"python3 extract_features.py \\\n      --input_file=input.txt \\\n      --output_file=output.jsonl \\\n      --vocab_file=uncased_L-12_H-768_A-12/vocab.txt \\\n      --bert_config_file=uncased_L-12_H-768_A-12/bert_config.json \\\n      --init_checkpoint=uncased_L-12_H-768_A-12/bert_model.ckpt \\\n      --layers=-1 \\\n      --max_seq_length=256 \\\n      --batch_size=8\")\n    \n    bert_output = pd.read_json(\"output.jsonl\", lines = True)\n\n    os.system(\"rm output.jsonl\")\n    os.system(\"rm input.txt\")\n\n    index = df.index\n    columns = [\"emb_A\", \"emb_B\", \"emb_P\", \"label\"]\n    emb = pd.DataFrame(index = index, columns = columns)\n    emb.index.name = \"ID\"\n    \n    for i in range(len(df)): # For each line in the data file\n        # get the words A, B, Pronoun. Convert them to lower case, since we're using the uncased version of BERT\n        P = df.loc[i,\"Pronoun\"].lower()\n        A = df.loc[i,\"A\"].lower()\n        B = df.loc[i,\"B\"].lower()\n\n        # For each word, find the offset not counting spaces. This is necessary for comparison with the output of BERT\n        P_offset = compute_offset_no_spaces(df.loc[i,\"Text\"], df.loc[i,\"Pronoun-offset\"])\n        A_offset = compute_offset_no_spaces(df.loc[i,\"Text\"], df.loc[i,\"A-offset\"])\n        B_offset = compute_offset_no_spaces(df.loc[i,\"Text\"], df.loc[i,\"B-offset\"])\n        # Figure out the length of A, B, not counting spaces or special characters\n        A_length = count_length_no_special(A)\n        B_length = count_length_no_special(B)\n\n        # Initialize embeddings with zeros\n        emb_A = np.zeros(768)\n        emb_B = np.zeros(768)\n        emb_P = np.zeros(768)\n\n        # Initialize counts\n        count_chars = 0\n        cnt_A, cnt_B, cnt_P = 0, 0, 0\n\n        features = pd.DataFrame(bert_output.loc[i,\"features\"])\n        \n        for j in range(2,len(features)):  # Iterate over the BERT tokens for the current line; we skip over the first 2 tokens, which don't correspond to words\n            token = features.loc[j,\"token\"]\n\n            # See if the character count until the current token matches the offset of any of the 3 target words\n            if count_chars  == P_offset: \n                # print(token)\n                emb_P += np.array(features.loc[j,\"layers\"][0]['values'])\n                cnt_P += 1\n            if count_chars in range(A_offset, A_offset + A_length): \n                # print(token)\n                emb_A += np.array(features.loc[j,\"layers\"][0]['values'])\n                cnt_A +=1\n            if count_chars in range(B_offset, B_offset + B_length): \n                # print(token)\n                emb_B += np.array(features.loc[j,\"layers\"][0]['values'])\n                cnt_B +=1\n            # Update the character count\n            count_chars += count_length_no_special(token)\n        # Taking the average between tokens in the span of A or B, so divide the current value by the count\t\n        emb_A /= cnt_A\n        emb_B /= cnt_B\n        \n        label = \"Neither\"\n        if (df.loc[i,\"A-coref\"] == 1):\n            label = \"A\"\n        if (df.loc[i,\"B-coref\"] == 1):\n            label = \"B\"\n\n        # Put everything together in emb\n        emb.iloc[i] = [emb_A, emb_B, emb_P, label]\n        \n    return emb\n\n\ndef parse_embeddings(embedding_df):\n    embedding_df.sort_index(inplace=True)\n    \n    X = np.zeros((len(embedding_df), 768 * 3))\n    Y = np.zeros((len(embedding_df), 3))\n    \n    for i in range(len(embedding_df)):\n        A = np.array(embedding_df.loc[i,\"emb_A\"])\n        B = np.array(embedding_df.loc[i,\"emb_B\"])\n        P = np.array(embedding_df.loc[i,\"emb_P\"])\n        X[i] = np.concatenate((A,B,P))\n        \n        label = embedding_df.loc[i, \"label\"]\n        \n        if label == 'A':\n            Y[i, 0] = 1\n        elif label == 'B':\n            Y[i, 1] = 1\n        else:\n            Y[i, 2] = 1\n            \n    return X, Y\n\n\ndef get_embedding_similarities(embedding_df):\n    embedding_df.sort_index(inplace=True)\n    \n    X = pd.DataFrame(index = embedding_df.index, columns = ['emb_sim_A_P', 'emb_sim_B_P'])\n    for i in range(len(embedding_df)):\n        A = np.array(embedding_df.loc[i,\"emb_A\"])\n        B = np.array(embedding_df.loc[i,\"emb_B\"])\n        P = np.array(embedding_df.loc[i,\"emb_P\"])\n        concat = np.concatenate((A, B, P))\n        \n        if np.sum(np.isnan(concat)):\n            continue\n\n        A = A.reshape(-1, 1)\n        B = B.reshape(-1, 1)\n        P = P.reshape(-1, 1)\n        X.loc[i, 'emb_sim_A_P'] = metrics.pairwise.cosine_similarity(A, P)\n        X.loc[i, 'emb_sim_B_P'] = metrics.pairwise.cosine_similarity(B, P)\n        \n    return X","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gap_development = pd.read_csv('../input/gapdatasetmaksym/gapdataset/gap-development.tsv', delimiter='\\t')\ngap_test = pd.read_csv('../input/gapdatasetmaksym/gapdataset/gap-test.tsv', delimiter='\\t')\ngap_validation = pd.read_csv('../input/gapdatasetmaksym/gapdataset/gap-validation.tsv', delimiter='\\t')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gap_development.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gap_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gap_validation.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def rename_labels(df):\n    df['A-coref'] = df['A-coref'].astype(int)\n    df['B-coref'] = df['B-coref'].astype(int)\n    df['Neither'] = 1.0 - (df['A-coref'] + df['B-coref'])\n    \n    \n# train = pd.concat((gap_test, gap_validation, gap_development)).reset_index(drop=True)\ntrain = pd.concat((gap_test, gap_validation)).reset_index(drop=True)\nrename_labels(train)\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Started at \", time.ctime())\n# test_emb = bert_embeddings(gap_test)\n# test_emb.to_json(\"contextual_embeddings_gap_test.json\", orient = 'columns')\n\n# validation_emb = bert_embeddings(gap_validation)\n# validation_emb.to_json(\"contextual_embeddings_gap_validation.json\", orient = 'columns')\n\ntrain_emb = bert_embeddings(train)\ntrain_emb.to_json(\"contextual_embeddings_train.json\", orient = 'columns')\n\ndevelopment_emb = bert_embeddings(gap_development)\ndevelopment_emb.to_json(\"contextual_embeddings_gap_development.json\", orient = 'columns')\nprint(\"Finished at \", time.ctime())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_bert = pd.read_json(\"contextual_embeddings_train.json\")\ndevelopment_bert = pd.read_json(\"contextual_embeddings_gap_development.json\")\n\nX_train, Y_train = parse_embeddings(train_bert)\nX_test, Y_test = parse_embeddings(development_bert)\n\n# Drop NaN\nremove_test = [row for row in range(len(X_test)) if np.sum(np.isnan(X_test[row]))]\nX_test = np.delete(X_test, remove_test, 0)\nY_test = np.delete(Y_test, remove_test, 0)\n\nremove_train = [row for row in range(len(X_train)) if np.sum(np.isnan(X_train[row]))]\nX_train = np.delete(X_train, remove_train, 0)\nY_train = np.delete(Y_train, remove_train, 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Text'] = train.apply(lambda r: name_replace(r['Text'], r['A'], 'subjectone'), axis=1)\ntrain['Text'] = train.apply(lambda r: name_replace(r['Text'], r['B'], 'subjecttwo'), axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Find top 5 the most often occurency tags"},{"metadata":{"trusted":true},"cell_type":"code","source":"tags = {}\nfor text in train['Text']:\n    doc = nlp(str(text))\n    for token in doc:\n        if token.text == 'subjectone' or token.text == 'subjecttwo':\n            if token.dep_ in tags:\n                tags[token.dep_] += 1\n            else:\n                tags[token.dep_] = 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sorted_tags = sorted(tags.items(), key=lambda kv: kv[1])\nsorted_tags[-5:]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Extend feature matrix"},{"metadata":{"trusted":true},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')\n\nadd_distance_features(train)\nadd_nlp_features_with_similarirty(train, ['poss', 'nsubj', 'pobj', 'dobj', 'conj'])\n\nadd_distance_features(gap_development)\nadd_nlp_features_with_similarirty(gap_development, ['poss', 'nsubj', 'pobj', 'dobj', 'conj'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sim_train = get_embedding_similarities(train_bert)\nsim_test = get_embedding_similarities(development_bert)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_col = [\n               'Pronoun-offset', \n#                'Pronoun-offset2', \n               'A-offset', \n#                'A-offset2', \n               'A-dist', \n               'B-offset', \n#                'B-offset2',\n               'B-dist', \n#                'section_min',  \n#                'section_max',\n               'A-poss', \n               'B-poss', \n               'A-nsubj',\n               'B-nsubj',\n               'A-pobj',\n               'B-pobj',\n               'A-dobj',\n               'B-dobj',\n               'A-conj',\n               'B-conj',\n               'A-word-offset',\n               'B-word-offset',\n               'Pronoun-word-offset',\n               'A-word-dist',\n               'B-word-dist',\n#                'emb_sim_A_P',\n#                'emb_sim_B_P'\n#                'A-with-P',\n#                'B-with-P'\n              ]\npred_col = ['A-coref', 'B-coref', 'Neither']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# drop rows which correspond to NaN rows in embeddings df\ntrain.drop(remove_train, axis=0, inplace=True)\ngap_development.drop(remove_test, axis=0, inplace=True)\n\nX_train = np.concatenate((train[feature_col], X_train), axis=1)\nX_test = np.concatenate((gap_development[feature_col], X_test), axis=1)\n\nprint(X_test.shape)\nprint(gap_development.shape)\n# x_train, x_test, y_train, y_test = model_selection.train_test_split(train[feature_col].fillna(-1), train[pred_col], test_size=0.2, random_state=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras import applications, layers, models, regularizers\nimport keras.backend as K\nfrom keras import callbacks as kc\nimport tensorflow as tf\nfrom sklearn.model_selection import cross_val_score, KFold\n\nbatch_size = 32\ndropout = 0.6\n\ndef create_conv1d(train_data):   \n    X_input = layers.Input(shape=(train_data.shape[1], 1))\n    \n    X = layers.Conv1D(128, 3)(X_input)\n    X = layers.BatchNormalization()(X)\n    X = layers.Activation('relu')(X)\n    X = layers.MaxPool1D()(X)\n    X = layers.Dropout(dropout, seed = 2)(X)\n    \n    X = layers.Dense(100)(X)\n    X = layers.BatchNormalization()(X)\n    X = layers.Activation('relu')(X)\n    X = layers.Dropout(dropout)(X)\n#     X = layers.Conv1D(64, 3, activation='relu')(X_input)\n#     X = layers.Conv1D(64, 3, activation='relu')(X)\n#     X = layers.BatchNormalization()(X)\n#     X = layers.Activation('relu')(X)\n#     X = layers.MaxPool1D(3)(X)\n#     X = layers.Dropout(dropout, seed = 2)(X)\n    \n#     X = layers.Conv1D(128, 3, activation='relu')(X)\n#     X = layers.Conv1D(128, 3, activation='relu')(X)\n#     X = layers.BatchNormalization()(X)\n#     X = layers.Activation('relu')(X)\n#     X = layers.MaxPool1D(3)(X)\n#     X = layers.Dropout(dropout, seed = 7)(X)\n    \n    X = layers.Flatten()(X)\n    X = layers.Dense(3, name = 'output', kernel_regularizer = regularizers.l2(0.1))(X)\n    X = layers.Activation('softmax')(X)\n\n    model = models.Model(input = X_input, output = X)\n    model.compile(optimizer='adam',\n                  loss='categorical_crossentropy', metrics=['accuracy'])\n    \n    return model\n\n\ndef create_mlp(train_data):\n    input_X = layers.Input([train_data.shape[1]])\n    \n    X = layers.Dense(150)(input_X)\n    X = layers.BatchNormalization()(X)\n    X = layers.Activation('relu')(X)\n    X = layers.Dropout(dropout)(X)\n    \n#     X = layers.Dense(200)(X)\n#     X = layers.BatchNormalization()(X)\n#     X = layers.Activation('relu')(X)\n#     X = layers.Dropout(dropout)(X)\n    \n    X = layers.Dense(3, kernel_regularizer = regularizers.l1(0.3))(X)\n    X = layers.Activation('softmax')(X)\n    \n    model = models.Model(input = input_X, output = X)\n    model.compile(optimizer='adam',\n                  loss='categorical_crossentropy', metrics=['accuracy'])\n    \n    return model\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_kfold(model, X_train, Y_train, name):\n    min_loss = 1.0\n    best_model = 0\n    folds = KFold(n_splits=5, shuffle=True, random_state=3)\n    val_scores = []\n    test_scores = []\n    os.system(\"rm {}_best_model_*\".format(name))\n    for fold_n, (train_index, valid_index) in enumerate(folds.split(X_train)):\n        X_tr = X_train[train_index]\n        X_val =  X_train[valid_index]\n        Y_tr = Y_train[train_index]\n        Y_val = Y_train[valid_index]\n\n        file_path = \"{}_best_model_{}.hdf5\".format(name, fold_n+1)\n        check_point = kc.ModelCheckpoint(file_path, monitor = \"val_loss\", save_best_only = True, mode = \"min\")\n        early_stopping = kc.EarlyStopping(monitor='val_loss', patience=50, mode='min', restore_best_weights=True)\n        callbacks = [check_point, early_stopping]\n\n        history = model.fit(X_tr, Y_tr, \n                epochs=1000, \n                batch_size=batch_size,\n                callbacks=callbacks,\n                validation_data=(X_val, Y_val),\n                verbose=1)\n        \n        if min(history.history['val_loss']) < min_loss:\n            min_loss = min(history.history['val_loss'])\n            best_model = fold_n + 1\n        \n    return best_model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# conv1d.fit(np.expand_dims(X_train,axis=2), Y_train,\n#           epochs=epochs,\n#           batch_size=batch_size)\n# print('Conv log_loss: ', metrics.log_loss(Y_test, conv1d.predict(np.expand_dims(X_test,axis=2))))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"conv1d = create_conv1d(np.expand_dims(X_train,axis=2))\nbest_conv1d = train_kfold(conv1d, np.expand_dims(X_train,axis=2), Y_train, \"conv1d\")\nconv1d.load_weights(\"./conv1d_best_model_{}.hdf5\".format(best_conv1d))\nprint('Conv log_loss: ', metrics.log_loss(Y_test, conv1d.predict(np.expand_dims(X_test,axis=2))))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mlp = create_mlp(X_train)\nbest_mlp = train_kfold(mlp, X_train, Y_train, \"mlp\")\nmlp.load_weights(\"./mlp_best_model_{}.hdf5\".format(best_mlp))\nprint('MLP log_loss: ', metrics.log_loss(Y_test, mlp.predict(X_test)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mlp2 = create_mlp(X_train)\nmlp2.fit(X_train, Y_train, epochs=20, batch_size=batch_size) \nprint('MLP log_loss: ', metrics.log_loss(Y_test, mlp2.predict(X_test)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# model = multiclass.OneVsRestClassifier(ensemble.RandomForestClassifier(max_depth = 7, n_estimators=2000, random_state=33))\nmodel = linear_model.LogisticRegression(penalty='l2', multi_class='multinomial')\nmodel.fit(X_train, Y_train)\nprint('log_loss: ', metrics.log_loss(Y_test, model.predict_proba(X_test)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# gap_development['A-coref'] = train['A-coref'].astype(int)\n# gap_development['B-coref'] = train['B-coref'].astype(int)\n# gap_development['NEITHER'] = 1.0 - (train['A-coref'] + train['B-coref'])\n# gap_development.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# add_additional_features(gap_development)\n# gap_development_x = gap_development[feature_col]\n# gap_development_y = gap_development[pred_col]\n# gap_development_pred = model.predict_proba(gap_development_x)\n# print('log_loss: ', metrics.log_loss(gap_development_y, gap_development_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# gap_development_y.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# gap_development_pred","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Submission test"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_sub1 = pd.read_csv('../input/gendered-pronoun-resolution/test_stage_1.tsv', delimiter='\\t')\nresults = model.predict_proba(test_sub1[feature_col])\ntest_sub1.rename(columns={'A': 'A_Noun', 'B': 'B_Noun'})\ntest_sub1['A'] = results[:,0]\ntest_sub1['B'] = results[:,1]\ntest_sub1['NEITHER'] = results[:,2]\ntest_sub1[['ID', 'A', 'B', 'Neither']].to_csv('submission1.csv', index=False)\ntest_sub1.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_sub2 = pd.read_csv('../input/gendered-pronoun-resolution/test_stage_2.tsv', delimiter='\\t')\nresults = model.predict_proba(test_sub2[feature_col])\ntest_sub2.rename(columns={'A': 'A_Noun', 'B': 'B_Noun'})\ntest_sub2['A'] = results[:,0].astype(np.float)\ntest_sub2['B'] = results[:,1].astype(np.float)\ntest_sub2['NEITHER'] = results[:,2].astype(np.float)\ntest_sub2[['ID', 'A', 'B', 'NEITHER']].to_csv('submission2.csv', index=False)\ntest_sub2.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_sub2 = pd.read_csv('../input/gendered-pronoun-resolution/test_stage_2.tsv', delimiter='\\t')\ntest_sub2.head()\n# results = model.predict(test_sub2[feature_col])\n# test_sub2.rename(columns={'A': 'A_Noun', 'B': 'B_Noun'})\n# test_sub2['A'] = results[:,0].astype(np.float)\n# test_sub2['B'] = results[:,1].astype(np.float)\n# test_sub2['NEITHER'] = results[:,2].astype(np.float)\n# test_sub2[['ID', 'A', 'B', 'NEITHER']].to_csv('submission2.csv', index=False)\n# test_sub2.head()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}